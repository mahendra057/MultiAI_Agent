{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" We are going to use the langraph to work on this multi ai agent project which this langraph is same like graph database principle which are nodes ,states and nodes are connected to each other so same like that when we are working on complex architecture like creating multi Ai agent  it should be build by langraph for this project iam considering the nodes like 1) Start 2) Query router (returns correct datasource based on user query) 3) LLM 4) End and these 4 nodes we are going to connect to create this complex project ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install langchain langgraph cassio # cassio helps me to initialize the Astra Database","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cassio\n\n## initailizing the Connection of AStraDB\nASTRA_DB_APPLICATION_TOKEN=\"AstraCS:LTahzqdyQntsoamhHDFMEnfk:ad613b63aec2\" # enter the \"AstraCS:...\" string found in in your Token JSON file\"\nASTRA_DB_ID=\"c747b0-9594d14bacdf\" # this id we can get it from AstraDB in Database section \ncassio.init(token=ASTRA_DB_APPLICATION_TOKEN,database_id=ASTRA_DB_ID)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:02:24.519432Z","iopub.execute_input":"2024-12-06T11:02:24.519826Z","iopub.status.idle":"2024-12-06T11:02:28.031707Z","shell.execute_reply.started":"2024-12-06T11:02:24.519793Z","shell.execute_reply":"2024-12-06T11:02:28.030518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install langchain_community\n!pip install -U tiktoken langchain-groq langchainhub langchain langgraph langchain_huggingface","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Build Index\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import WebBaseLoader\n\n\n### from langchain_cohere import CohereEmbeddings\n\n\n\n# Docs to index\nurls = [\n    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n]\n\n# Load\ndocs = [WebBaseLoader(url).load() for url in urls]\ndocs_list = [item for sublist in docs for item in sublist]\nprint(docs_list)\n\n# Split The tiktoken encoder is a tokenizer and encoding tool\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n    chunk_size=500, chunk_overlap=0\n)\ndoc_splits = text_splitter.split_documents(docs_list)\n\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_huggingface import HuggingFaceEmbeddings\nembeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Connecting the embeddings to Astradb database \nfrom langchain.vectorstores.cassandra import Cassandra\nastra_vector_store=Cassandra(\n    embedding=embeddings,\n    table_name=\"qa_mini_demo\", # In this table in Astradb iam going to store the vectors of documents \n    session=None,\n    keyspace=None\n\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.indexes.vectorstore import VectorStoreIndexWrapper  # \nastra_vector_store.add_documents(doc_splits) # Whatever the documents we extracted from url we are going to save in astradb vector database by this line of code\nprint(\"Inserted %i headlines.\" % len(doc_splits))\n\nastra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store) # On top of astravector database i have created an index wrapper so that we can able to interact with vector database, in order to use vector database on top of index wrapper we need to use as_retriever()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"retriever=astra_vector_store.as_retriever()\nretriever.invoke(\"what is agent\")","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Router is a path,  based on user query router tells in which way router path needs to go or recognise and responde appropriate (Vector knowledge database or wiki_search) w.rt user query\n\nfrom typing import Literal  # It allows restricting a variable’s possible values to a specific set of literal values. In this case, it limits datasource to two valid options: \"vectorstore\" and \"wiki_search\".\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel, Field  # RouteQuery Class A Pydantic data model (BaseModel) defining the expected structure of the output from the language model (LLM). Output must contain a datasource field with either \"vectorstore\" or \"wiki_search\".\n\n# Data model\nclass RouteQuery(BaseModel): # RouteQuery A schema or data model that defines the structure of the output the LLM should produce\n    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n\n    datasource: Literal[\"vectorstore\", \"wiki_search\"] = Field(\n        ...,\n        description=\"Given a user question choose to route it to wikipedia or a vectorstore.\",\n    )  # this datasource is key and Literal are the structred values  of output which llm needs to return any one of them based on user query + system context llm understand the whole context and it returns output in structured manner by adhering to Literals values as output\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LLM with function call\nfrom langchain_groq import ChatGroq\nimport os\n\ngroq_api_key=\"gsk_lMbTWeLY7HFG4mjQly5YRKT\"\nos.environ[\"GROQ_API_KEY\"]=groq_api_key\nllm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:02:05.268637Z","iopub.execute_input":"2024-12-06T11:02:05.269054Z","iopub.status.idle":"2024-12-06T11:02:05.300537Z","shell.execute_reply.started":"2024-12-06T11:02:05.269018Z","shell.execute_reply":"2024-12-06T11:02:05.299299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# At the end of the day whatever output that I'm actually getting it should be in this particular format so here I'm going to create a variable called as structured lmore router is equal to llm dot with structured so there inside the llm is something called as with structured output and I'm going to use my route query over here okay I'm basically going  to call my route query class okay\nstructured_llm_router = llm.with_structured_output(RouteQuery)  # So in this way of structure here integrated the llm to the RouterQuery class, This is an LLM-based router, typically used to classify or decide on the next action based on the query. It uses a structured approach to output a decision or classification. For example: Determining the source of information: wiki_search vs. vectorstore. Routing questions based on domain expertise (e.g., technical vs. general queries). Outputting a structured response, such as: json Copy code { \"datasource\": \"wiki_search\", \"confidence\": 0.92 }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prompt\nsystem = \"\"\"You are an expert at routing a user question to a vectorstore or wikipedia.\nThe vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\nUse the vectorstore for questions on these topics. Otherwise, use wiki-search.\"\"\"\nroute_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system),\n        (\"human\", \"{question}\"),\n    ]\n)\n\n\nquestion_router = route_prompt | structured_llm_router  # Pipe (|) Operator The | operator creates a pipeline where the output of the first function (route_prompt) is passed as input to the second function (structured_llm_router).\n #------------- or ---------\n#question_router = structured_llm_router(route_prompt(question))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Lets test the RouterQuery class \nprint(\n    question_router.invoke(\n        {\"question\": \"who is ms dhoni\"}\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:40:21.981506Z","iopub.execute_input":"2024-12-06T10:40:21.981928Z","iopub.status.idle":"2024-12-06T10:40:22.421107Z","shell.execute_reply.started":"2024-12-06T10:40:21.981896Z","shell.execute_reply":"2024-12-06T10:40:22.419377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:04:32.476153Z","iopub.execute_input":"2024-12-06T11:04:32.476620Z","iopub.status.idle":"2024-12-06T11:04:32.894711Z","shell.execute_reply.started":"2024-12-06T11:04:32.476581Z","shell.execute_reply":"2024-12-06T11:04:32.893523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"By the above  2 user query my class RouterQuery is working well to choose the appropriate path or source(vector DB or wikipedia)  w.r.t user query ","metadata":{}},{"cell_type":"code","source":"!pip install wikipedia","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Working With Tools\nfrom langchain_community.utilities import WikipediaAPIWrapper\nfrom langchain_community.tools import WikipediaQueryRun\n\napi_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=1000)\nwiki=WikipediaQueryRun(api_wrapper=api_wrapper)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:49:07.327280Z","iopub.execute_input":"2024-12-06T09:49:07.327778Z","iopub.status.idle":"2024-12-06T09:49:07.333943Z","shell.execute_reply.started":"2024-12-06T09:49:07.327739Z","shell.execute_reply":"2024-12-06T09:49:07.332754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wiki.run(\"who is virat kohli\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:49:09.459480Z","iopub.execute_input":"2024-12-06T09:49:09.459896Z","iopub.status.idle":"2024-12-06T09:49:10.113030Z","shell.execute_reply.started":"2024-12-06T09:49:09.459861Z","shell.execute_reply":"2024-12-06T09:49:10.111649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I'm going to create a graph state which will be my class which is inheriting type dict and this will be in the form of key value pairs like question is equal to Sting generation is equal to  and documents list of s Str okay so I'm basically creating three variables this variables will be responsible in managing the entire state of AI AGent that I have actually created so it represents the state of a graph attributes are this many things okay so for right now just keep a note of that okay\n\n## Graph\n\nfrom typing import List\n\nfrom typing_extensions import TypedDict # TypedDict is a Python construct that allows you to define the structure of a dictionary, including the expected keys and their data types.\n\n \nclass GraphState(TypedDict):  # The GraphState is a data structure that represents the state of the query processing workflow. It is used to store and manage information that flows through the nodes of the workflow. GraphState acts as a \"state container\" to track: What the user asked. The AI model's response. Any relevant documents retrieved during the process.\n    \"\"\"\n    Represents the state of our graph.\n\n    Attributes:\n        question: question\n        generation: LLM generation\n        documents: list of documents\n    \"\"\"\n\n    question: str         # The user's query as a string (e.g., \"What is agent?\").\n    generation: str       # The response or output generated by the LLM as a string.\n    documents: List[str]  #  A list of documents (as strings) retrieved from the vector store or other sources like Wikipedia.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##  Nodes\nfrom langchain.schema import Document\n\n\ndef retrieve(state): # The retrieve function updates the GraphState by fetching relevant documents from the vector store for the given question.  the state we passed as parameter its a type of graph state which we defined in the above cell which the graph state have 3 variables which are question, generation, documents\n    \"\"\"\n    Retrieve documents\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): New key added to state, documents, that contains retrieved documents\n    \"\"\"\n    print(\"---RETRIEVE---\")\n    question = state[\"question\"]\n\n    # Retrieval\n    documents = retriever.invoke(question)\n    return {\"documents\": documents, \"question\": question}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Nodes\ndef wiki_search(state):\n    \"\"\"\n    wiki search based on the re-phrased question.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): Updates documents key with appended web results\n    \"\"\"\n\n    print(\"---wikipedia---\")\n    print(\"---HELLO--\")\n    question = state[\"question\"]\n    print(question)\n\n    # Wiki search\n    docs = wiki.invoke({\"query\": question})\n    #print(docs[\"summary\"])\n    wiki_results = docs\n    wiki_results = Document(page_content=wiki_results)\n\n    return {\"documents\": wiki_results, \"question\": question}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Edges ###\n\n\ndef route_question(state):\n    \"\"\"\n    Route question to wiki search or RAG.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        str: Next node to call\n    \"\"\"\n\n    print(\"---ROUTE QUESTION---\")  # Key Points: Inputs: state: Contains the question. Process: Uses the question_router (integrated with an LLM) to decide where to send the query: wiki_search: For general knowledge or out-of-domain queries. vectorstore: For specific topics stored in the vector database. Output: Returns the next node to execute: \"wiki_search\" or \"vectorstore\".\n    question = state[\"question\"]\n    source = question_router.invoke({\"question\": question})\n    if source.datasource == \"wiki_search\":\n        print(\"---ROUTE QUESTION TO Wiki SEARCH---\")\n        return \"wiki_search\"\n    elif source.datasource == \"vectorstore\":\n        print(\"---ROUTE QUESTION TO RAG---\")\n        return \"vectorstore\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langgraph.graph import END, StateGraph, START\n\nworkflow = StateGraph(GraphState)\n# Define the nodes\nworkflow.add_node(\"wiki_search\", wiki_search)  # Key is the name of the node and wiki_search is the fucntion name of the node which contains the functionality of wiki_search which we defined in the above cell web search\nworkflow.add_node(\"retrieve\", retrieve)  # retrieve  , same applies here\n\n# Build graph\nworkflow.add_conditional_edges(\n    START,\n    route_question,  \n    {\n        \"wiki_search\": \"wiki_search\",  # same like below\n        \"vectorstore\": \"retrieve\",   #  here we define the condition in graph flow if the user query is related to vectorstore then corresponded value which is node name will get implemented\n    },\n) \n\n# after the user query corresponded flow got executed then now we need Edges to add the both node  flow edges to End Stage \nworkflow.add_edge( \"retrieve\", END)  \nworkflow.add_edge( \"wiki_search\", END)\n# Compile\napp = workflow.compile()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:17:32.475698Z","iopub.execute_input":"2024-12-06T11:17:32.476223Z","iopub.status.idle":"2024-12-06T11:17:32.486455Z","shell.execute_reply.started":"2024-12-06T11:17:32.476168Z","shell.execute_reply":"2024-12-06T11:17:32.484980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\ntry:\n    display(Image(app.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # This requires some extra dependencies and is optional\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:38:58.080828Z","iopub.execute_input":"2024-12-06T10:38:58.082072Z","iopub.status.idle":"2024-12-06T10:38:58.167894Z","shell.execute_reply.started":"2024-12-06T10:38:58.082028Z","shell.execute_reply":"2024-12-06T10:38:58.166699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pprint import pprint\n\n# Run\ninputs = {\n    \"question\": \"What is an agent?\"\n}\nfor output in app.stream(inputs):\n    for key, value in output.items():\n        # Node\n        pprint(f\"Node '{key}':\")\n        # Optional: print full state at each node\n        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n    pprint(\"\\n---\\n\")\n\n# Final generation\npprint(value['documents'][0].dict()['metadata']['description'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:20:23.312972Z","iopub.execute_input":"2024-12-06T11:20:23.313374Z","iopub.status.idle":"2024-12-06T11:20:23.873464Z","shell.execute_reply.started":"2024-12-06T11:20:23.313340Z","shell.execute_reply":"2024-12-06T11:20:23.872362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pprint import pprint\n\n# Run\ninputs = {\n    \"question\": \"who is virat kohli\"\n}\nfor output in app.stream(inputs):\n    for key, value in output.items():\n        # Node\n        pprint(f\"Node '{key}':\")\n        # Optional: print full state at each node\n        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n    pprint(\"\\n---\\n\")\n\n# Final generation\npprint(value['documents'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:02:06.011071Z","iopub.execute_input":"2024-12-06T12:02:06.011483Z","iopub.status.idle":"2024-12-06T12:02:06.782758Z","shell.execute_reply.started":"2024-12-06T12:02:06.011447Z","shell.execute_reply":"2024-12-06T12:02:06.781592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Your code snippet demonstrates how to integrate LangChain with AstraDB and build a sophisticated routing and querying system. Here's a summary and breakdown of its components:\n\n---\n\n### 1. **AstraDB Initialization**\nYou initialized a connection to an **AstraDB vector database** using the `cassio` library. This is critical for storing and retrieving embeddings.\n\n### 2. **Document Loading and Preprocessing**\n- Loaded documents from specified URLs using the `WebBaseLoader`.\n- Split the documents into smaller chunks using the `RecursiveCharacterTextSplitter` with a `tiktoken` encoder for effective storage and retrieval in the vector database.\n\n---\n\n### 3. **Embeddings and Vector Database**\n- Used **HuggingFaceEmbeddings** (`all-MiniLM-L6-v2`) to convert text chunks into vectors.\n- Stored these vectors in the AstraDB vector store (`qa_mini_demo` table).\n\n---\n\n### 4. **Routing Logic**\n- **RouterQuery Class**: A Pydantic model that determines whether a user query should go to the vector database or Wikipedia based on the content of the query.\n- **LLM Integration**:\n  - You integrated a **Groq-based LLM** to route questions intelligently.\n  - Created a structured prompt to guide the model in deciding whether to route to the vector store or Wikipedia.\n\n---\n\n### 5. **Graph Workflow**\nYou built a **graph workflow** using LangGraph that manages the state and processes queries through nodes:\n- **Nodes**:\n  - `wiki_search`: Fetches information from Wikipedia.\n  - `retrieve`: Retrieves relevant documents from the vector database.\n- **Routing**:\n  - Dynamically routes the user query based on the `question_router` output.\n  - Routes to either `wiki_search` or `retrieve` depending on the question's context.\n- **Graph Compilation**:\n  - Defined `START` and `END` nodes for the workflow.\n  - Dynamically decides the next node to call based on the routing logic.\n\n---\n\n### 6. **Running the Workflow**\n- Input: A question such as *\"What is agent?\"*.\n- Process:\n  - The question is routed through the graph workflow.\n  - Either fetches a document from the vector database or a Wikipedia summary.\n- Output: Retrieved information based on the selected path.\n\n---\n\n### 7. **Additional Features**\n- The `GraphState` class keeps track of:\n  - The query (`question`).\n  - LLM's generated responses (`generation`).\n  - Retrieved documents (`documents`).\n\n- **Final Output**:\n  - The retrieved documents and their metadata (e.g., description) are displayed.\n\n","metadata":{}},{"cell_type":"code","source":"{\n  \"clientId\": \"LTahDFMEnfk\",\n  \"secret\": \"3NF_cE3vhSpBqH,lt\",\n  \"token\": \"AstraCS:LTc561f5c3e9613b63aec2\"\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Working explaiantion\n\n### **Code Flow Explanation**\n\nThis code implements a **stateful workflow** for processing user queries using a graph-based model. The workflow routes the query to the appropriate node (either `wiki_search` or `retrieve`), processes the query, and collects relevant documents before ending the execution. Here's a detailed breakdown:\n\n---\n\n### **1. Key Components**\n\n#### **a. `GraphState`**\n- Defines the state structure of the workflow.\n- It contains:\n  - **`question`**: User's query (string).\n  - **`generation`**: Output generated by the AI (string; initially empty).\n  - **`documents`**: List of documents retrieved during the workflow (list of strings).\n\n---\n\n#### **b. Functions (Nodes)**\nEach function corresponds to a \"node\" in the workflow graph.\n\n1. **`route_question(state)`**\n   - Determines the next step based on the query.\n   - Routes queries to either:\n     - `wiki_search`: For general knowledge.\n     - `vectorstore`: For domain-specific information in the vector store.\n\n2. **`wiki_search(state)`**\n   - Fetches relevant results from Wikipedia for the given question.\n   - Updates the `documents` field in the `GraphState`.\n\n3. **`retrieve(state)`**\n   - Retrieves documents related to the query from the vector store.\n   - Updates the `documents` field in the `GraphState`.\n\n---\n\n#### **c. `StateGraph`**\n- Implements the entire workflow as a directed graph with nodes and edges.\n- Nodes correspond to the functions (`wiki_search`, `retrieve`).\n- Edges represent transitions based on conditions (`route_question`).\n\n---\n\n### **2. Workflow Construction**\n\n1. **Define Nodes**:\n   - `wiki_search` for Wikipedia queries.\n   - `retrieve` for vector store queries.\n\n2. **Add Conditional Edges**:\n   - The **START node** determines the route using `route_question`.\n   - Routes:\n     - `\"wiki_search\"` → `wiki_search` node.\n     - `\"vectorstore\"` → `retrieve` node.\n\n3. **Add Final Edges**:\n   - Both `wiki_search` and `retrieve` lead to the **END node**.\n\n4. **Compile Workflow**:\n   - `app = workflow.compile()` creates an executable version of the workflow.\n\n---\n\n### **3. Code Execution**\n\n#### **Input**\n```python\ninputs = {\"question\": \"What is an agent?\"}\n```\n- The user's query is \"What is an agent?\".\n\n#### **Flow**\n\n1. **Initial State**:\n   - `GraphState` is initialized:\n     ```python\n     state = {\n         \"question\": \"What is an agent?\",\n         \"generation\": \"\",\n         \"documents\": []\n     }\n     ```\n\n2. **Routing Decision** (`route_question`):\n   - The query is passed to `question_router`.\n   - Assuming the query is domain-specific, the router returns `\"vectorstore\"`.\n\n3. **Retrieve Documents** (`retrieve`):\n   - The `retriever` fetches documents related to \"What is an agent?\".\n   - Example:\n     ```python\n     state[\"documents\"] = [\n         \"An agent is a software program that acts on behalf of a user.\",\n         \"Agents in AI often refer to entities that perceive the environment and act.\"\n     ]\n     ```\n\n4. **Final State**:\n   - After processing, the state contains the updated `documents`:\n     ```python\n     {\n         \"question\": \"What is an agent?\",\n         \"generation\": \"\",\n         \"documents\": [\n             \"An agent is a software program that acts on behalf of a user.\",\n             \"Agents in AI often refer to entities that perceive the environment and act.\"\n         ]\n     }\n     ```\n\n---\n\n### **4. Output Example**\n\nDuring execution, each node’s state is printed:\n\n#### **Step-by-Step Console Output**\n```plaintext\nNode 'route_question':\n---ROUTE QUESTION---\n---ROUTE QUESTION TO RAG---\n\nNode 'retrieve':\n---RETRIEVE---\n```\n\n- **Final Output**:\n   ```plaintext\n   Node 'retrieve':\n   Documents Retrieved:\n   - \"An agent is a software program that acts on behalf of a user.\"\n   - \"Agents in AI often refer to entities that perceive the environment and act.\"\n   ```\n\n---\n\n### **5. Modifications for `wiki_search`**\n\nIf the query is routed to `wiki_search` (e.g., \"Who is MS Dhoni?\"), the workflow fetches Wikipedia results:\n- Example:\n   ```python\n   state[\"documents\"] = [\"MS Dhoni is a former Indian cricketer and captain.\"]\n   ```\n\n---\n\n### **Summary**\nThe workflow dynamically processes queries and routes them based on content:\n1. Determines the route (`wiki_search` or `vectorstore`).\n2. Fetches relevant documents.\n3. Produces a structured final state with documents retrieved.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Comparison: `pprint` vs `print`**\n\n#### **Data Structure**\n```python\ndata = {\n    \"name\": \"Alice\",\n    \"age\": 30,\n    \"hobbies\": [\"reading\", \"cycling\", \"hiking\"],\n    \"address\": {\n        \"city\": \"New York\",\n        \"zip_code\": \"10001\",\n        \"coordinates\": {\"lat\": 40.7128, \"long\": -74.0060}\n    }\n}\n```\n\n---\n\n#### **Using `print`**\n```plaintext\n{'name': 'Alice', 'age': 30, 'hobbies': ['reading', 'cycling', 'hiking'], 'address': {'city': 'New York', 'zip_code': '10001', 'coordinates': {'lat': 40.7128, 'long': -74.006}}}\n```\n\n---\n\n#### **Using `pprint`**\n```plaintext\n{\n    'name': 'Alice',\n    'age': 30,\n    'hobbies': ['reading', 'cycling', 'hiking'],\n    'address': {\n        'city': 'New York',\n        'zip_code': '10001',\n        'coordinates': {'lat': 40.7128, 'long': -74.006}\n    }\n}\n```","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}